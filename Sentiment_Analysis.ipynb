{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:52\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "labels = {'pos' : 1, 'neg' : 0}\n",
    "pbar = pyprind.ProgBar(50000)\n",
    "df = pd.DataFrame()\n",
    "for s in ('test', 'train'):\n",
    "    for l in ('pos', 'neg'):\n",
    "        path = os.path.join('aclImdb', s, l)\n",
    "        for file in sorted(os.listdir(path)):\n",
    "            with open(os.path.join(path, file), \n",
    "                     'r', encoding = 'utf-8') as infile:\n",
    "                txt = infile.read()\n",
    "            df = df.append([[txt, labels[l]]], ignore_index = True)\n",
    "            pbar.update()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I went and saw this movie last night after bei...          1\n",
       "1  Actor turned director Bill Paxton follows up h...          1\n",
       "2  As a recreational golfer with some knowledge o...          1\n",
       "3  I saw this film in a sneak preview, and it is ...          1\n",
       "4  Bill Paxton has taken the true story of the 19...          1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Towards the end of the movie, I felt it was to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>This is the kind of movie that my enemies cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I saw 'Descent' last night at the Stockholm Fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Some films that you pick up for a pound turn o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>This is one of the dumbest films, I've ever se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  Towards the end of the movie, I felt it was to...          0\n",
       "49996  This is the kind of movie that my enemies cont...          0\n",
       "49997  I saw 'Descent' last night at the Stockholm Fi...          0\n",
       "49998  Some films that you pick up for a pound turn o...          0\n",
       "49999  This is one of the dumbest films, I've ever se...          0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.to_csv('movie_data.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was taken to this film by a friend and was s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This trash version of `Romeo and Juliet' passe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There is a lot to like in this film, despite i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>People have often been uncomfortable with \"The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't get this. The movie obviously has a pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I opted to see the film at the recent Dubai Fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jamie Foxx does a fine job of impersonating th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The oddly-named Vera-Ellen was to movie dancin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>First of all, the entire script is mostly impr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great gangster film.Sam Mendes has directed ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I was taken to this film by a friend and was s...          1\n",
       "1  This trash version of `Romeo and Juliet' passe...          1\n",
       "2  There is a lot to like in this film, despite i...          1\n",
       "3  People have often been uncomfortable with \"The...          1\n",
       "4  I don't get this. The movie obviously has a pr...          0\n",
       "5  I opted to see the film at the recent Dubai Fi...          0\n",
       "6  Jamie Foxx does a fine job of impersonating th...          1\n",
       "7  The oddly-named Vera-Ellen was to movie dancin...          0\n",
       "8  First of all, the entire script is mostly impr...          1\n",
       "9  A great gangster film.Sam Mendes has directed ...          1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movie_data.csv', encoding = 'utf-8')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()\n",
    "docs = np.array(['The sun is shining',\n",
    "                'The weather is sweet', \n",
    "                'The sun is shining, the weather is sweet,',\n",
    "                'and one and one is two'])\n",
    "bag = count.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 6, 'sun': 4, 'is': 1, 'shining': 3, 'weather': 8, 'sweet': 5, 'and': 0, 'one': 2, 'two': 7}\n"
     ]
    }
   ],
   "source": [
    "print(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 0 1 0 0]\n",
      " [0 1 0 0 0 1 1 0 1]\n",
      " [0 2 0 1 1 1 2 0 1]\n",
      " [2 1 2 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.38 0.   0.57 0.57 0.   0.46 0.   0.  ]\n",
      " [0.   0.38 0.   0.   0.   0.57 0.46 0.   0.57]\n",
      " [0.   0.46 0.   0.35 0.35 0.35 0.56 0.   0.35]\n",
      " [0.66 0.17 0.66 0.   0.   0.   0.   0.33 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer(use_idf = True, \n",
    "                        norm = 'l2',\n",
    "                        smooth_idf = True)\n",
    "np.set_printoptions(precision = 2)\n",
    "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a film that I will promote to all who will listen.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'review'][-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                          text)\n",
    "    text = (re.sub('[\\W]+',' ', text.lower())) + ' '.join(emoticons).replace('-', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a film that i will promote to all who will listen \n",
      " to the first group my vote is eight \n",
      "0s high school melodrama or 70s kitsch in general \n",
      "ther testament to what a great actor al pacino is \n",
      "d actually and eels come one really \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(preprocessor(df.loc[i, 'review'][-50:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'a', 'test', 'example']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('This is a test example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_porter('runners like running and thus they run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'run', 'lot']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "[w for w in tokenizer_porter('a runner likes running and runs a lot') if w not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df.loc[:25000, 'review'].values\n",
    "y_train = df.loc[:25000, 'sentiment'].values\n",
    "X_test = df.loc[25000:, 'review'].values\n",
    "y_test = df.loc[25000:, 'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents = None, lowercase = False, preprocessor = None)\n",
    "param_grid = [{'vect__ngram_range' : [(1,1)],\n",
    "              'vect__stop_words' : [stop, None],\n",
    "              'vect__tokenizer' : [tokenizer, tokenizer_porter],\n",
    "              'clf__penalty' : ['l1', 'l2'], \n",
    "              'clf__C' : [1.0, 10.0, 100.0]}]\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                    ('clf', LogisticRegression(random_state = 42, solver = 'liblinear'))])\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, scoring = 'accuracy', cv = 3, verbose = 3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 38.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=False,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acc...\n",
       "                                                'you', \"you're\", \"you've\",\n",
       "                                                \"you'll\", \"you'd\", 'your',\n",
       "                                                'yours', 'yourself',\n",
       "                                                'yourselves', 'he', 'him',\n",
       "                                                'his', 'himself', 'she',\n",
       "                                                \"she's\", 'her', 'hers',\n",
       "                                                'herself', 'it', \"it's\", 'its',\n",
       "                                                'itself', ...],\n",
       "                                               None],\n",
       "                          'vect__tokenizer': [<function tokenizer at 0x7f6e6d83d598>,\n",
       "                                              <function tokenizer_porter at 0x7f6e69d1cae8>]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs_lr_tfidf.pkl']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(gs_lr_tfidf, 'gs_lr_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_lr_clf = gs_lr_tfidf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9878804847806087\n",
      "precision: 0.9876318084515976\n",
      "recall: 0.9883370358616312\n",
      "f1_score: 0.9879842963080462\n"
     ]
    }
   ],
   "source": [
    "y_prediction = best_lr_clf.predict(X_train)\n",
    "print('Accuracy:', accuracy_score(y_train, y_prediction))\n",
    "print('precision:', precision_score(y_train, y_prediction))\n",
    "print('recall:', recall_score(y_train, y_prediction))\n",
    "print('f1_score:', f1_score(y_train, y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAEGCAYAAABhHPB4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRARQGIiIpzAQEUBhICKewkBEAPg/2FoFiZcHgUIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_train, y_prediction)\n",
    "plot_confusion_matrix(conf_mat)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "false_positives = X_train[(y_train == 0) & (y_prediction == 1)]\n",
    "false_negatives = X_train[(y_train == 1) & (y_prediction == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a young woman comes to the home town of his husband after he passed away in an accident she barely settles down in this small town but shortly after loses her little son in a kidnapping and all her hopes this could lead to all kinds following plots in a normal movie find a new partner and being happy finally or depressed enough to struggle and finally kill herself she does try to kill herself but not after a series of severe fights with god she trusts in god only to find that god seems to forgive everyone even the killer well i should be careful here about god the movie doesn t mean a thing against god the way the movie deals the issue is quite interesting not in the woman s point of view or from god s perspective in this way there would be lots of grass growing clouds flying views i suppose rather it s from a third party s eye the movie let us to perceive and doesn t explain a thing the movie wouldn t be so interesting were there only the woman there s this man who s everywhere around the woman and obviously in love with her but in his own way he s a funny guy like a clown i should say who shamelessly hangs around our heroine the combination of these two the woman full of tension crying and throwing up always and the man smiling and talking stupidly ends up in a good balance of emotions nothing absurdly wrong or too tedious highly recommend '"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      after seeing forever hollywood it would be nat...\n",
       "1      the story goes something like this a small tow...\n",
       "2      you know i always fancy disturbing or strange ...\n",
       "3      this is without a doubt the most hilarious mov...\n",
       "4      another day this movie requires you to watch i...\n",
       "                             ...                        \n",
       "151    yes the movie is not a piece of art but the fi...\n",
       "152    what can i say i m a secret fan of over the to...\n",
       "153    how much can you really say about a condom wit...\n",
       "154    rip off of scream or especially i know what yo...\n",
       "155    stone has tried another type of movie any give...\n",
       "Name: 0, Length: 156, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.89768\n",
      "test recall: 0.9070742921674598\n",
      "test precision: 0.8888625405106315\n",
      "test f1 score: 0.8978760779303736\n"
     ]
    }
   ],
   "source": [
    "y_test_prediction = gs_lr_tfidf.predict(X_test)\n",
    "print('test accuracy:', accuracy_score(y_test, y_test_prediction))\n",
    "print('test recall:', recall_score(y_test, y_test_prediction))\n",
    "print('test precision:', precision_score(y_test, y_test_prediction))\n",
    "print('test f1 score:', f1_score(y_test, y_test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=42, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_line_svm = Pipeline([('vectorizer', tfidf),\n",
    "                         ('clf', SVC(kernel = 'rbf', random_state = 42))])\n",
    "pipe_line_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "#joblib.dump(pipe_line_svm, 'pipe_line_svm.pkl')\n",
    "pipe_line_svm = joblib.load('pipe_line_svm.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prediction = pipe_line_svm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_predictions.pkl']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_prediction, 'svm_predictions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9915603375864965\n",
      "precision: 0.9905010686297792\n",
      "recall: 0.992780069819105\n",
      "f1_score: 0.9916392598169355\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(y_train, y_prediction))\n",
    "print('precision:', precision_score(y_train, y_prediction))\n",
    "print('recall:', recall_score(y_train, y_prediction))\n",
    "print('f1_score:', f1_score(y_train, y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAEGCAYAAABhHPB4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4j0SP9ydigAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_train, y_prediction)\n",
    "plot_confusion_matrix(conf_mat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test.pkl']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X_train, 'X_train.pkl')\n",
    "joblib.dump(y_train, 'y_train.pkl')\n",
    "joblib.dump(X_test, 'X_test.pkl')\n",
    "joblib.dump(y_test, 'y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "X_train = joblib.load('X_train.pkl')\n",
    "y_train = joblib.load('y_train.pkl')\n",
    "X_test = joblib.load('X_test.pkl')\n",
    "y_test = joblib.load('y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'vectorizer__ngram_range' : [(1,1)],\n",
    "              'vectorizer__stop_words' : [stop, None],\n",
    "              'vectorizer__tokenizer' : [tokenizer, tokenizer_porter],\n",
    "              'clf__C' : [.1, 1, 10]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search_cv = GridSearchCV(estimator = pipe_line_svm, param_grid = param_grid, verbose = 3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_cv = GridSearchCV(estimator = pipe_line_svm, param_grid=param_grid,cv = 3, scoring = 'accuracy', verbose = 3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 90.1min\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 151.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vectorizer',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=False,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        str...\n",
       "                                                      \"you'll\", \"you'd\", 'your',\n",
       "                                                      'yours', 'yourself',\n",
       "                                                      'yourselves', 'he', 'him',\n",
       "                                                      'his', 'himself', 'she',\n",
       "                                                      \"she's\", 'her', 'hers',\n",
       "                                                      'herself', 'it', \"it's\",\n",
       "                                                      'its', 'itself', ...],\n",
       "                                                     None],\n",
       "                          'vectorizer__tokenizer': [<function tokenizer at 0x7fabfdffba60>,\n",
       "                                                    <function tokenizer_porter at 0x7fabfdffbd08>]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_grid_search.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(grid_search_cv, 'svm_grid_search.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm = grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "     max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
       "     verbose=False),\n",
       " 'clf__C': 10,\n",
       " 'clf__break_ties': False,\n",
       " 'clf__cache_size': 200,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__coef0': 0.0,\n",
       " 'clf__decision_function_shape': 'ovr',\n",
       " 'clf__degree': 3,\n",
       " 'clf__gamma': 'scale',\n",
       " 'clf__kernel': 'rbf',\n",
       " 'clf__max_iter': -1,\n",
       " 'clf__probability': False,\n",
       " 'clf__random_state': 42,\n",
       " 'clf__shrinking': True,\n",
       " 'clf__tol': 0.001,\n",
       " 'clf__verbose': False,\n",
       " 'memory': None,\n",
       " 'steps': [('vectorizer',\n",
       "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                   input='content', lowercase=False, max_df=1.0, max_features=None,\n",
       "                   min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                   smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                   sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=<function tokenizer at 0x7fabfdffba60>, use_idf=True,\n",
       "                   vocabulary=None)),\n",
       "  ('clf',\n",
       "   SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "       decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "       max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
       "       verbose=False))],\n",
       " 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=False, max_df=1.0, max_features=None,\n",
       "                 min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                 sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=<function tokenizer at 0x7fabfdffba60>, use_idf=True,\n",
       "                 vocabulary=None),\n",
       " 'vectorizer__analyzer': 'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': 'strict',\n",
       " 'vectorizer__dtype': numpy.float64,\n",
       " 'vectorizer__encoding': 'utf-8',\n",
       " 'vectorizer__input': 'content',\n",
       " 'vectorizer__lowercase': False,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__norm': 'l2',\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__smooth_idf': True,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__sublinear_tf': False,\n",
       " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': <function __main__.tokenizer>,\n",
       " 'vectorizer__use_idf': True,\n",
       " 'vectorizer__vocabulary': None,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_svm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_svm_predictions.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred, 'best_svm_predictions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "f1_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(y_train, y_pred))\n",
    "print('precision:', precision_score(y_train, y_pred))\n",
    "print('recall:', recall_score(y_train, y_pred))\n",
    "print('f1_score:', f1_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9022\n",
      "Precision: 0.8914411579609818\n",
      "Recall: 0.9140921190610631\n",
      "F1 score 0.9026245569317775\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(y_test, y_test_pred))\n",
    "print('Precision:', precision_score(y_test, y_test_pred))\n",
    "print('Recall:', recall_score(y_test, y_test_pred))\n",
    "print('F1 score', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
